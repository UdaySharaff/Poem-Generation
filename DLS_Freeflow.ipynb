{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1c-hRDZgmoH",
    "outputId": "90d3e125-31f5-44d0-f42f-ee2152e7f1c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-12 07:38:09--  https://raw.githubusercontent.com/Bjarten/early-stopping-pytorch/master/pytorchtools.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2109 (2.1K) [text/plain]\n",
      "Saving to: ‘pytorchtools.py’\n",
      "\n",
      "\r",
      "pytorchtools.py       0%[                    ]       0  --.-KB/s               \r",
      "pytorchtools.py     100%[===================>]   2.06K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-12-12 07:38:09 (50.9 MB/s) - ‘pytorchtools.py’ saved [2109/2109]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "!wget https://raw.githubusercontent.com/Bjarten/early-stopping-pytorch/master/pytorchtools.py\n",
    "from pytorchtools import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-9pB6jglg4co",
    "outputId": "70e2db7f-2b15-403c-84ce-f35a698c0a59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zm6DYiPi1y9n"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Oy4QHIMyh3X0"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/dls/kaggle_poem_dataset.csv', 'r') as file:\n",
    "  text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gXlmVPpcpMm9"
   },
   "outputs": [],
   "source": [
    "class RNN_LSTM(nn.Module):        \n",
    "  def __init__(self, dim):\n",
    "    super().__init__()\n",
    "    self.lstm_layer=nn.LSTM(dim,256,2, dropout=0.5,batch_first=True)\n",
    "    self.dropout=nn.Dropout(0.5)\n",
    "    self.linear_layer=nn.Linear(256,dim)\n",
    "\n",
    "  def forward(self, x, hidden):\n",
    "    r_output, hidden = self.lstm_layer(x, hidden)\n",
    "    out = self.dropout(r_output)\n",
    "    out = out.contiguous().view(-1, 256)\n",
    "    out = self.linear_layer(out)\n",
    "    return out, hidden\n",
    "\n",
    "  def initialise(self, batch_size):\n",
    "    initials = next(self.parameters()).data\n",
    "    hidden = (initials.new(2, batch_size, 256).zero_().to(device),\n",
    "              initials.new(2, batch_size, 256).zero_().to(device))\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jyfSwmhskHAf"
   },
   "outputs": [],
   "source": [
    "def load(encoded_Values, batchsize, s):\n",
    "  batchsize_total = batchsize * s\n",
    "  batches = len(encoded_Values)//batchsize_total\n",
    "  encoded_Values = encoded_Values[:batches * batchsize_total]\n",
    "  encoded_Values = encoded_Values.reshape((batchsize, -1))\n",
    "  for n in range(0, encoded_Values.shape[1], s):\n",
    "    inputs = encoded_Values[:, n:n+s]\n",
    "    targets = np.zeros_like(inputs)\n",
    "    if n+s<len(encoded_Values):\n",
    "      targets[:, :-1], targets[:, -1] = inputs[:, 1:], encoded_Values[:, n+s]\n",
    "    else:\n",
    "      targets[:, :-1], targets[:, -1] = inputs[:, 1:], encoded_Values[:, 0]\n",
    "    yield inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "v2nb25iOjtNH"
   },
   "outputs": [],
   "source": [
    "def encode_onehot(data, n):\n",
    "  encodedVal = np.zeros((data.size, n), dtype=np.float32)\n",
    "  encodedVal[np.arange(encodedVal.shape[0]), data.flatten()] = 1.\n",
    "  encodedVal = encodedVal.reshape((*data.shape, n))\n",
    "  return encodedVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LYKs00N9-NZn"
   },
   "outputs": [],
   "source": [
    "chars = tuple(set(text))\n",
    "charVersion = dict(enumerate(chars))\n",
    "intVersion = {c: i for i, c in charVersion.items()}\n",
    "encoded = np.array([intVersion[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8SgrENYl4Emk"
   },
   "outputs": [],
   "source": [
    "def train(model, encoded_Values, epochs=100, batchsize=10, s=50):\n",
    "  early_stopping = EarlyStopping(patience=4, verbose=True)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  split = int(len(encoded_Values)*(0.9))\n",
    "  trainData, testData = encoded_Values[:split], encoded_Values[split:]\n",
    "  dim = len(chars);print(dim)\n",
    "  for epoch in range(epochs):\n",
    "      h = model.initialise(batchsize)\n",
    "      trainLoss =[]\n",
    "      for x, y in load(trainData, batchsize, s):\n",
    "          x = encode_onehot(x, dim)\n",
    "          inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
    "          inputs, targets = inputs.to(device), targets.to(device)\n",
    "          h = tuple([each.data for each in h])\n",
    "          optimizer.zero_grad()\n",
    "          predicted, h = model(inputs, h)\n",
    "          loss = criterion(predicted, targets.view(batchsize*s).long())\n",
    "          loss.backward()\n",
    "          trainLoss.append(loss.item())\n",
    "          nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "          optimizer.step()\n",
    "      with torch.no_grad():\n",
    "          h = model.initialise(batchsize)\n",
    "          testLoss = []\n",
    "          for x, y in load(testData, batchsize, s):\n",
    "              x = encode_onehot(x, dim)\n",
    "              x, y = torch.from_numpy(x), torch.from_numpy(y)\n",
    "              h = tuple([each.data for each in h])\n",
    "              inputs, targets = x, y\n",
    "              inputs, targets = inputs.to(device), targets.to(device)\n",
    "              predicted, h = model(inputs, h)\n",
    "              val_loss = criterion(predicted, targets.view(batchsize*s).long())          \n",
    "              testLoss.append(val_loss.item())\n",
    "      early_stopping(np.mean(testLoss), model)\n",
    "      if early_stopping.early_stop:\n",
    "              print(\"Early stopping\")\n",
    "              break\n",
    "      model.load_state_dict(torch.load('checkpoint.pt'))                        \n",
    "      print(\"Epoch: {}/{}   \".format(epoch+1, epochs),\"Train Loss: {:.4f}\".format(np.mean(trainLoss)),\"Test Loss: {:.4f}\".format(np.mean(testLoss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EZB-ldluQbyt"
   },
   "outputs": [],
   "source": [
    "model = RNN_LSTM(len(chars)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRIBD-DoQ4T2"
   },
   "outputs": [],
   "source": [
    "train(model, encoded, epochs=100, batchsize=256, s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vLUN4gMnR085"
   },
   "outputs": [],
   "source": [
    "def test(char, hidden_layer=None, rank=None):  \n",
    "    inputs = np.array([[intVersion[char]]])\n",
    "    inputs = encode_onehot(inputs, len(chars))\n",
    "    inputs = torch.from_numpy(inputs).to(device)        \n",
    "    hidden_layer_to_tuple = []\n",
    "    for unit in hidden_layer:\n",
    "      hidden_layer_to_tuple.append(unit.data)\n",
    "    hidden_layer_to_tuple = tuple(hidden_layer_to_tuple)\n",
    "    predicted, hidden_layer = model(inputs, hidden_layer_to_tuple)\n",
    "    predicted = F.softmax(predicted, dim=1).data.cpu()\n",
    "    predicted, t = predicted.topk(rank)\n",
    "    t = np.squeeze(t.numpy())\n",
    "    predicted = predicted.numpy().squeeze()\n",
    "    char = np.random.choice(t, p=predicted/predicted.sum())\n",
    "    return charVersion[char], hidden_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibN50-Z8ze-8",
    "outputId": "fd804409-2e10-40d2-9be2-b1c28e4d7408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
      "RNN_LSTM(\n",
      "  (lstm_layer): LSTM(310, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (linear_layer): Linear(in_features=256, out_features=310, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "IYP-ENZLV17W"
   },
   "outputs": [],
   "source": [
    "def writePoem(length, key='The', rank=3):\n",
    "  with torch.no_grad():    \n",
    "    poem = [char for char in key]\n",
    "    hidden_layer = model.initialise(1)\n",
    "    for c in key:\n",
    "      char, hidden_layer = test(c, hidden_layer, rank=rank)\n",
    "    poem.append(char)\n",
    "    for _ in range(length):\n",
    "      char, hidden_layer = test(poem[-1], hidden_layer, rank=rank)\n",
    "      poem.append(char)\n",
    "  return ''.join(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IoXSn5pZWhI3",
    "outputId": "194af45f-9f10-440a-eeb3-1cd90dff0d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunshine to the stranger of all the winds and the the straicers of a book to the station of the soul of the star of the statues.\n",
      "\n",
      "They wake to streng that some on to my father, and the body is to see the stars.\n",
      "The war they were the stone of the straighters and the sea will see the shells of the trees,\n",
      "the sourness of a sea that was a body of stands and streeches on a chicken.\n",
      "\n",
      "A stretched of-tree and the second throat in the world, and the water walks\n",
      "the stars, a change to another and the thing of so ending\n",
      "to a story of a stranger than the seasons, that wait all that they see\n",
      "the shadows and then she thinks the things the said in a stracket of the solid\n",
      "and she had standing their streams and the stood short translations, the strange stars\n",
      "she watched the street and the sun shoots through a country that wat send\n",
      "and tractline the black brain and a third stars of a core shell of the sanks\n",
      "to see his tree and the state of the shining story, the words of the streath\n",
      "\n",
      "or to the stars to the stars\n"
     ]
    }
   ],
   "source": [
    "print(writePoem(length = 1000, key='Sunshine', rank=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNUpWwA_pjj3",
    "outputId": "b32888d7-2ba5-48e6-ca40-17158a7b44d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree to the stone.\n",
      "\n",
      "And I ame the tops of the sound\n",
      "And the shot of the stone starts a soul\n",
      "\n",
      "The soul was a promonty, a secord that to still\n",
      "To the flast that the state of the tongue\n",
      "Of a car the the content of the strength, a breath\n",
      "And streams are towels, and shakes a star of thinks\n",
      "To see the water on the shore and till the straight\n",
      "Shall be an art of stars. The stone wits she says, the world still said,\n",
      "That the strain will be the sound, the seans in a conden and store,\n",
      "And that was the body on a thing of the seas of the track.\n",
      "\n",
      "I wanted the books of a care of the stars, and the same state of the sea,\n",
      "I saw the body of this to the way they are an and thighs, a strange shade\n",
      "They start and they say, that to still say it is and the stream of sound\n",
      "In the stars are a concert to still seem an end of things to the sea of ale the star,\n",
      "And we think the sound of the stream too much and the shadows and shot to man stink themselves.\n",
      "They were a shoulder of their song and the stars of the sad sac\n"
     ]
    }
   ],
   "source": [
    "print(writePoem(length = 1000, key='Tree', rank=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fd_Q23TG3Rf2",
    "outputId": "d60cc16a-acf9-4763-d605-1d8183ccf7f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Son\n",
      "And the steam,\n",
      "And the stranded through the soul\n",
      "And the traces of stars.\n",
      "\n",
      "The shape is the tree,\n",
      "And all a treacherical streets\n",
      "The station said. The content of him\n",
      "A sound of the stream of soldier, the book\n",
      "And the stars of him and stone\n",
      "A shallow south of the stranger,\n",
      "They were searched to the shadow.\n",
      "The shore with the body of the state\n",
      "Of a street and stone and stars,\n",
      "And the company of high streets\n",
      "And the shoulder to see,\n",
      "And when the stars and sheets around to set the streets,\n",
      "The blood on their strains all the sea\n",
      "That the beneath the sea stones a star,\n",
      "And shall be the streaming stars,\n",
      "To star the stream of the stream.\n",
      "The words are the back of the stone, and the storm\n",
      "Of the shadows of the way that she was and too some still soul,\n",
      "And when I stopped a beard and the blank take of the window\n",
      "The cold star and the street and too shoulders and things.\n",
      "The warm thiss that was a brick and the stars\n",
      "\n",
      "The body and so that was a bone of the stair.\n",
      "They still bring the stars and \n"
     ]
    }
   ],
   "source": [
    "print(writePoem(length = 1000, key='The', rank=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8ywge293X2_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "free.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
